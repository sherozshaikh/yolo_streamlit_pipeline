{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Yc-_FFmcQOe"
      },
      "source": [
        "#### Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRPK6KZa6f6_",
        "outputId": "8524e0a0-6b70-4365-81ee-98fdfde382ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m872.8/872.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --q streamlit ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr1rzr1w7HCh",
        "outputId": "af0dab93-3eb8-48fc-fc58-cbaf77deb17e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h\n",
            "added 22 packages, and audited 23 packages in 4s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues, run:\n",
            "  npm audit fix\n",
            "\n",
            "Run `npm audit` for details.\n"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hv_4ijsciag"
      },
      "source": [
        "#### Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0Zb42z2b4Mh",
        "outputId": "3d453877-2f6a-40ec-9a7f-e6371d2e0c56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "import glob\n",
        "import zipfile\n",
        "import yaml\n",
        "import shutil\n",
        "import random\n",
        "import cv2\n",
        "from datetime import datetime\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "from io import StringIO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision.ops import nms\n",
        "from tensorflow.keras.preprocessing.image import apply_affine_transform\n",
        "\n",
        "YOLO_LOGO_PATH = './Gemini_Generated_Image.jpg'\n",
        "col1, col2, col3 = st.columns([1, 2, 1])\n",
        "with col2:\n",
        "    st.image(YOLO_LOGO_PATH, use_column_width=False, width=240)\n",
        "\n",
        "st.title(\"YOLO Model Training and Inference\")\n",
        "st.write(\"This app allows you to train YOLO models or run inference using your dataset. Select an option below to get started.\")\n",
        "st.markdown(\"---\")\n",
        "option = st.selectbox('What would you like to do today?',('Select Option', 'Train YOLO Model', 'Run Inference', 'Annotation Adjuster'))\n",
        "\n",
        "if option == 'Train YOLO Model':\n",
        "    st.header('YOLO Model Training Phase')\n",
        "    st.write(\"Welcome to the YOLO model training phase. Please follow the steps below to set up your training.\")\n",
        "\n",
        "    def remove_directory(directory_path):\n",
        "\n",
        "        if os.path.exists(directory_path):\n",
        "            try:\n",
        "                shutil.rmtree(directory_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Error: {e}\")\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    def update_yaml_file_paths():\n",
        "\n",
        "        with open('./session_files/uploaded_yaml.yaml', 'r') as file:\n",
        "            data = yaml.safe_load(file)\n",
        "\n",
        "        data['train'] = './train/images'\n",
        "        data['val'] = './valid/images'\n",
        "        data['test'] = './test/images'\n",
        "\n",
        "        with open('./session_files/uploaded_yaml.yaml', 'w') as file:\n",
        "            yaml.safe_dump(data, file, default_flow_style=False)\n",
        "\n",
        "    def validate_yolo_model_file(pt_file_path):\n",
        "        try:\n",
        "            model = YOLO(pt_file_path)\n",
        "            st.success(\"The uploaded .pt file is a valid YOLO model.\")\n",
        "        except Exception as e:\n",
        "            st.error(\"The uploaded .pt file is not a valid YOLO model\")\n",
        "\n",
        "    parent_directory = './session_files'\n",
        "    remove_directory(parent_directory)\n",
        "    os.makedirs(parent_directory, exist_ok=True)\n",
        "    progress_tracker = [\"1. Select Model Or Uplaod Custom Model\", \"2. Upload YAML\", \"3. Upload Images\", \"4. Data Manipulation\", \"5. Training Phase\"]\n",
        "    current_progress = len([step for step in progress_tracker if step]) / len(progress_tracker)\n",
        "    st.progress(current_progress)\n",
        "    st.subheader(\"Step 1: Select or Upload YOLO Model\")\n",
        "    model_choice = st.radio(\"Choose how you'd like to proceed:\", ('Select Pre-trained Model', 'Upload Custom Model'))\n",
        "    selected_model = None\n",
        "    custom_model = False\n",
        "    if model_choice == 'Select Pre-trained Model':\n",
        "        selected_models = {\n",
        "            'yolov8n.pt': 'YOLOv8-N (Nano) ~3.2 M Params',\n",
        "            'yolov8s.pt': 'YOLOv8-S (Small) ~11.2 M Params',\n",
        "            'yolov8m.pt': 'YOLOv8-M (Medium) ~25.9 M Params',\n",
        "            'yolov8l.pt': 'YOLOv8-L (Large) ~43.7 M Params',\n",
        "            'yolov8x.pt': 'YOLOv8-X (Extra-large) ~68.2 M Params',\n",
        "            'yolov10n.pt': 'YOLOv10-N (Nano) ~2.3 M Params',\n",
        "            'yolov10s.pt': 'YOLOv10-S (Small) ~7.2 M Params',\n",
        "            'yolov10m.pt': 'YOLOv10-M (Medium) ~15.4 M Params',\n",
        "            'yolov10l.pt': 'YOLOv10-L (Large) ~24.4 M Params',\n",
        "            'yolov10x.pt': 'YOLOv10-X (Extra-large) ~29.5 M Params',\n",
        "        }\n",
        "        selected_model = st.selectbox('Choose a pre-trained YOLO model', list(selected_models.keys()), format_func=lambda x: selected_models[x])\n",
        "        st.success(f\"Using pre-trained model: {selected_model} for training.\")\n",
        "    elif model_choice == 'Upload Custom Model':\n",
        "        st.subheader('Step 1: Upload the YOLO Model (.pt)')\n",
        "        model_file = st.file_uploader(\"Upload YOLO .pt model file\", type=['pt'], help=\"Upload the YOLO model (.pt format) to run inference or continue training.\")\n",
        "        if model_file:\n",
        "            custom_model = True\n",
        "            with open('./session_files/custom_model.pt', \"wb\") as f:\n",
        "                f.write(model_file.getbuffer())\n",
        "            validate_yolo_model_file('./session_files/custom_model.pt')\n",
        "        else:\n",
        "            st.warning(\"Please upload your YOLO model (.pt) file to continue.\")\n",
        "    st.subheader(\"Step 2: Upload the YAML File\")\n",
        "    yaml_file = st.file_uploader(\"Upload YAML file\", type=['yaml', 'yml'])\n",
        "    dataset_directory = None\n",
        "\n",
        "    if yaml_file:\n",
        "        with open(file='./session_files/uploaded_yaml.yaml', mode=\"wb\") as f:\n",
        "            f.write(yaml_file.getbuffer())\n",
        "        update_yaml_file_paths()\n",
        "        stringio = StringIO(yaml_file.getvalue().decode(\"utf-8\"))\n",
        "        yaml_content = yaml.safe_load(stringio)\n",
        "\n",
        "        if all(key in yaml_content for key in ['train', 'val', 'test', 'nc', 'names']):\n",
        "            st.success(\"YAML file is valid.\")\n",
        "            st.write(f\"Number of classes: {yaml_content['nc']}\")\n",
        "            st.write(f\"Classes: {', '.join(yaml_content['names'])}\")\n",
        "        else:\n",
        "            st.error(\"YAML file missing required fields.\")\n",
        "\n",
        "    st.header('Step 3: Upload Training, Validation, and Testing Images')\n",
        "    image_zip = st.file_uploader(\"Upload image zip file\", type=['zip'])\n",
        "    dataset_directory = os.path.join(os.getcwd(), 'session_files')\n",
        "\n",
        "    def check_folder_structure(extracted_folder):\n",
        "        required_structure = {\n",
        "            \"train\": [\"images\", \"labels\"],\n",
        "            \"valid\": [\"images\", \"labels\"],\n",
        "            \"test\": [\"images\", \"labels\"]\n",
        "        }\n",
        "        structure_status = {}\n",
        "        for main_folder, subfolders in required_structure.items():\n",
        "            main_folder_path = os.path.join(extracted_folder, main_folder)\n",
        "            if not os.path.exists(main_folder_path):\n",
        "                structure_status[main_folder] = False\n",
        "            else:\n",
        "                structure_status[main_folder] = all(os.path.exists(os.path.join(main_folder_path, subfolder)) for subfolder in subfolders)\n",
        "        return structure_status\n",
        "\n",
        "    def display_structure_result(structure_status):\n",
        "        st.write(\"### Your Uploaded Structure:\")\n",
        "        for folder, status in structure_status.items():\n",
        "            symbol = \"✅\" if status else \"❌\"\n",
        "            st.write(f\"{symbol} {folder}/\")\n",
        "\n",
        "            if status:\n",
        "                st.write(f\"  - {folder}/images/\")\n",
        "                st.write(f\"  - {folder}/labels/\")\n",
        "        st.write(\"### Correct Structure:\")\n",
        "        st.write(\"\"\"\n",
        "        - train/\n",
        "            - images/\n",
        "            - labels/\n",
        "        - valid/\n",
        "            - images/\n",
        "            - labels/\n",
        "        - test/\n",
        "            - images/\n",
        "            - labels/\n",
        "        \"\"\")\n",
        "\n",
        "    if image_zip is not None:\n",
        "        temp_extract_dir = './session_files/test_structure/'\n",
        "        with zipfile.ZipFile(image_zip, 'r') as zip_ref:\n",
        "            zip_ref.extractall(temp_extract_dir)\n",
        "        st.success(\"Images unzipped successfully!\")\n",
        "        structure_status = check_folder_structure(temp_extract_dir)\n",
        "        if all(structure_status.values()):\n",
        "            for item in os.listdir(temp_extract_dir):\n",
        "                shutil.move(os.path.join(temp_extract_dir, item), os.path.join(parent_directory, item))\n",
        "            shutil.rmtree(temp_extract_dir)\n",
        "            valid_extensions = ('.jpg', '.jpeg', '.png')\n",
        "            for path1 in ['/train/images', '/valid/images', '/test/images']:\n",
        "                for filename in os.path.join(parent_directory, path1):\n",
        "                    if not filename.lower().endswith(valid_extensions):\n",
        "                        try:\n",
        "                            os.remove(os.path.join(parent_directory, path1, filename))\n",
        "                        except Exception as e:\n",
        "                            continue\n",
        "            train_images = os.listdir(os.path.join(dataset_directory, 'train/images'))\n",
        "            train_count = len(train_images)\n",
        "            test_images = os.listdir(os.path.join(dataset_directory, 'test/images'))\n",
        "            test_count = len(test_images)\n",
        "            val_images = os.listdir(os.path.join(dataset_directory, 'valid/images'))\n",
        "            val_count = len(val_images)\n",
        "            st.write(f\"Train images: {train_count}\")\n",
        "            st.write(f\"Validation images: {val_count}\")\n",
        "            st.write(f\"Test images: {test_count}\")\n",
        "            for idx,filename in enumerate(train_images):\n",
        "              if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                sample_image_path = filename\n",
        "                break\n",
        "            sample_image = cv2.imread(os.path.join(dataset_directory, 'train/images', sample_image_path))\n",
        "            sample_image_rgb = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
        "        else:\n",
        "            st.error(\"The uploaded zip file does not have the correct structure. Please check the details below:\")\n",
        "            display_structure_result(structure_status)\n",
        "            shutil.rmtree(temp_extract_dir)\n",
        "    else:\n",
        "        train_count = 0\n",
        "        st.write(\"No images uploaded yet.\")\n",
        "\n",
        "    st.header('Step 4: Data Manipulation')\n",
        "    if 'selected_techniques' not in st.session_state:\n",
        "        st.session_state.selected_techniques = {}\n",
        "    if 'try_technique' not in st.session_state:\n",
        "        st.session_state.try_technique = None\n",
        "    if 'technique_values' not in st.session_state:\n",
        "        st.session_state.technique_values = []\n",
        "    data_manipulation = st.radio(\"Do you want to apply data manipulation?\", [\"No\", \"Yes\"], index=0)\n",
        "\n",
        "    def apply_manipulation(image, manipulation, value):\n",
        "        if manipulation == 'Add Noise':\n",
        "            noise = np.random.normal(loc=0, scale=value/100, size=image.shape).astype('uint8')\n",
        "            return cv2.add(image, noise)\n",
        "        elif manipulation == 'Brightness':\n",
        "            hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "            hsv[:, :, 2] = cv2.add(hsv[:, :, 2], value)\n",
        "            return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
        "        elif manipulation == 'Contrast':\n",
        "            return cv2.convertScaleAbs(image, alpha=1 + value/100, beta=0)\n",
        "        elif manipulation == 'Flip Horizontally':\n",
        "            return cv2.flip(image, 1) if value > 0 else image\n",
        "        elif manipulation == 'Flip Vertically':\n",
        "            return cv2.flip(image, 0) if value > 0 else image\n",
        "        elif manipulation == 'Rotate':\n",
        "            return apply_affine_transform(image, theta=value)\n",
        "        elif manipulation == 'Zoom':\n",
        "            return apply_affine_transform(image, zx=1 + value/100, zy=1 + value/100)\n",
        "        elif manipulation == 'Shear':\n",
        "            return apply_affine_transform(image, shear=value)\n",
        "\n",
        "    manipulations = {\n",
        "        'Add Noise': (0, 100, 0),\n",
        "        'Brightness': (0, 100, 0),\n",
        "        'Contrast': (0, 100, 0),\n",
        "        'Flip Horizontally': (0, 360, 0),\n",
        "        'Flip Vertically': (0, 360, 0),\n",
        "        'Rotate': (0, 360, 0),\n",
        "        'Zoom': (0, 100, 0),\n",
        "        'Shear': (0, 100, 0),\n",
        "    }\n",
        "\n",
        "    if data_manipulation == \"Yes\" and train_count > 0:\n",
        "        st.subheader(\"Select and Try Manipulation Techniques\")\n",
        "        available_techniques = {k: v for k, v in manipulations.items() if k not in st.session_state.selected_techniques}\n",
        "        manipulation_choice = st.selectbox(\"Choose a technique to apply:\", list(available_techniques.keys()), index=0)\n",
        "        if manipulation_choice:\n",
        "            st.subheader(f\"Testing {manipulation_choice}\")\n",
        "            min_val, max_val, default_val = manipulations[manipulation_choice]\n",
        "            slider_value = st.slider(f\"Adjust {manipulation_choice}:\", min_value=min_val, max_value=max_val, value=default_val)\n",
        "            manipulated_image = apply_manipulation(sample_image_rgb, manipulation_choice, slider_value)\n",
        "            st.image(manipulated_image, caption=f\"Preview: {manipulation_choice} with value {slider_value}\", use_column_width=True)\n",
        "            if st.button(\"Add Technique\", key=\"add_technique\"):\n",
        "                st.session_state.selected_techniques[manipulation_choice] = slider_value\n",
        "                st.session_state.technique_values.append({'Technique': manipulation_choice, 'Value': slider_value})\n",
        "        if st.session_state.technique_values:\n",
        "            st.subheader(\"Added Techniques\")\n",
        "            df_transformations = pd.DataFrame(st.session_state.technique_values)\n",
        "            st.table(df_transformations)\n",
        "            if st.button(\"Apply Techniques to Training Data\"):\n",
        "                train_images_path = './session_files/train/images/'\n",
        "                train_labels_path = './session_files/train/labels/'\n",
        "                valid_extensions = ('.jpg', '.jpeg', '.png')\n",
        "                for img_name in os.listdir(train_images_path):\n",
        "                    if img_name.lower().endswith(valid_extensions):\n",
        "                        img_path = os.path.join(train_images_path, img_name)\n",
        "                        img = cv2.imread(img_path)\n",
        "                        for technique, value in st.session_state.selected_techniques.items():\n",
        "                            manipulated_img = apply_manipulation(img, technique, value)\n",
        "                            new_img_name = f\"{os.path.splitext(img_name)[0]}_{technique.lower()}.png\"\n",
        "                            new_img_path = os.path.join(train_images_path, new_img_name)\n",
        "                            cv2.imwrite(new_img_path, manipulated_img)\n",
        "                            label_name = os.path.splitext(img_name)[0] + '.txt'\n",
        "                            new_label_name = f\"{os.path.splitext(img_name)[0]}_{technique.lower()}.txt\"\n",
        "                            if os.path.exists(os.path.join(train_labels_path, label_name)):\n",
        "                                shutil.copy(os.path.join(train_labels_path, label_name), os.path.join(train_labels_path, new_label_name))\n",
        "                current_date = datetime.now().strftime(\"%Y%m%d\")\n",
        "                if custom_model:\n",
        "                    model_base_name = model_file.name.split('.')[0]\n",
        "                else:\n",
        "                    model_base_name = selected_model.split('.')[0]\n",
        "                csv_filename = f\"{model_base_name}_transformation_log_{current_date}.csv\"\n",
        "                df_transformations.to_csv(path_or_buf=f'./session_files/{csv_filename}', header=True, encoding='utf-8', mode='w', index=False)\n",
        "                st.success(f\"All selected techniques have been applied to the training data.\")\n",
        "                st.success(f\"Train images: {((df_transformations.shape[0]*train_count) + train_count)}\")\n",
        "    else:\n",
        "        st.write(f\"Train images: {train_count}\")\n",
        "\n",
        "    st.header('Step 5: Train the Model')\n",
        "    epochs = st.number_input('Enter number of epochs for training:', min_value=1, max_value=100, value=1, step=1)\n",
        "    if epochs > 10:\n",
        "        st.warning(\"You have selected more than 10 epochs. Training may take a long time depending on the model.\", icon=\"⚠️\")\n",
        "    if st.button(\"Train\"):\n",
        "        st.write(\"Training in progress...\")\n",
        "        try:\n",
        "            if torch.cuda.is_available():\n",
        "                st.warning(\"Training will be done on GPU\")\n",
        "                device = torch.device('cuda')\n",
        "            else:\n",
        "                st.warning(\"Training will be done on CPU\")\n",
        "                device = torch.device('cpu')\n",
        "            start_time = time.time()\n",
        "            if not custom_model:\n",
        "                model = YOLO(selected_model).to(device)\n",
        "            else:\n",
        "                model = YOLO('./session_files/custom_model.pt').to(device)\n",
        "            model.train(data=os.path.join(os.getcwd(), 'session_files', 'uploaded_yaml.yaml'), epochs=epochs, device=device)\n",
        "            total_time = time.time() - start_time\n",
        "            total_time_minutes = total_time / 60\n",
        "            total_time_hours = total_time / 3600\n",
        "            st.success(f\"Training completed successfully in ~{total_time_minutes:.2f} minutes / ~{total_time_hours:.2f} hours.\")\n",
        "            current_date = datetime.now().strftime(\"%Y%m%d\")\n",
        "            trained_model_folder = f\"./session_files/TrainedModel_{current_date}\"\n",
        "            if not os.path.exists(trained_model_folder):\n",
        "                os.makedirs(trained_model_folder)\n",
        "            if custom_model:\n",
        "                model_filename = f\"{model_file.name.split('.')[0]}_epochs{epochs}.pt\"\n",
        "            else:\n",
        "                model_filename = f\"{selected_model.split('.')[0]}_epochs{epochs}.pt\"\n",
        "            trained_model_path = os.path.join(trained_model_folder, model_filename)\n",
        "            model.save(trained_model_path)\n",
        "            if os.path.exists('/content/runs'):\n",
        "                shutil.move('/content/runs', trained_model_folder)\n",
        "            else:\n",
        "                pass\n",
        "            csv_file_path = glob.glob('./session_files/*_transformation_log_*.csv')\n",
        "            if csv_file_path:\n",
        "                shutil.move(csv_file_path[0], trained_model_folder)\n",
        "            else:\n",
        "                pass\n",
        "            zip_filename = f\"{trained_model_folder.replace('./session_files/','')}.zip\"\n",
        "            shutil.make_archive(trained_model_folder.replace('./session_files/',''), 'zip', trained_model_folder)\n",
        "            with open(zip_filename, 'rb') as f:\n",
        "                st.download_button('Download Model', f, file_name=zip_filename)\n",
        "        except Exception as e:\n",
        "            st.error(f\"An error occurred during training: {str(e)}\")\n",
        "\n",
        "elif option == 'Run Inference':\n",
        "    st.header(\"YOLO Model Inference Phase\")\n",
        "    st.write(\"You can run YOLO inference on uploaded images.\")\n",
        "    st.markdown(\"---\")\n",
        "    progress_tracker = [\"1. Select Model\", \"2. Upload Images\", \"6. Run Inference\"]\n",
        "    current_progress = len([step for step in progress_tracker if step]) / len(progress_tracker)\n",
        "    st.progress(current_progress)\n",
        "\n",
        "    def check_test_folder_structure(extracted_folder):\n",
        "        required_structure = {\n",
        "            \"test\": [\"images\"]\n",
        "        }\n",
        "        structure_status = {}\n",
        "        for main_folder, subfolders in required_structure.items():\n",
        "            main_folder_path = os.path.join(extracted_folder, main_folder)\n",
        "            if not os.path.exists(main_folder_path):\n",
        "                structure_status[main_folder] = False\n",
        "            else:\n",
        "                structure_status[main_folder] = all(os.path.exists(os.path.join(main_folder_path, subfolder)) for subfolder in subfolders)\n",
        "        return structure_status\n",
        "\n",
        "    def display_test_structure_result(structure_status):\n",
        "        st.write(\"### Your Uploaded Structure:\")\n",
        "        for folder, status in structure_status.items():\n",
        "            symbol = \"✅\" if status else \"❌\"\n",
        "            st.write(f\"{symbol} {folder}/\")\n",
        "            if status:\n",
        "                st.write(f\"  - {folder}/images/\")\n",
        "        st.write(\"### Correct Structure:\")\n",
        "        st.write(\"\"\"\n",
        "        - test/\n",
        "            - images/\n",
        "        \"\"\")\n",
        "\n",
        "    def remove_directory(directory_path):\n",
        "        if os.path.exists(directory_path):\n",
        "            try:\n",
        "                shutil.rmtree(directory_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Error: {e}\")\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    def filter_and_merge_boxes(boxes, scores, threshold=0.7):\n",
        "        scores = np.array(scores)\n",
        "        indices = np.where(scores > threshold)[0]\n",
        "        filtered_boxes = [boxes[i] for i in indices]\n",
        "        filtered_scores = [scores[i] for i in indices]\n",
        "        if len(filtered_boxes) == 0:\n",
        "            return [], []\n",
        "        boxes = np.array(filtered_boxes)\n",
        "        scores = np.array(filtered_scores)\n",
        "        boxes_tensor = torch.tensor(boxes, dtype=torch.float32)\n",
        "        scores_tensor = torch.tensor(scores, dtype=torch.float32)\n",
        "        keep = nms(boxes_tensor, scores_tensor, iou_threshold=0.5)\n",
        "        merged_boxes = boxes[keep.numpy()].tolist()\n",
        "        merged_scores = scores[keep.numpy()].tolist()\n",
        "        return merged_boxes, merged_scores\n",
        "\n",
        "    def validate_yolo_model_file(pt_file_path):\n",
        "        try:\n",
        "            model = YOLO(pt_file_path)\n",
        "            st.success(\"The uploaded .pt file is a valid YOLO model.\")\n",
        "        except Exception as e:\n",
        "            st.error(\"The uploaded .pt file is not a valid YOLO model\")\n",
        "\n",
        "    parent_directory = './session_files'\n",
        "    remove_directory(parent_directory)\n",
        "    os.makedirs(parent_directory, exist_ok=True)\n",
        "    st.subheader('Step 1: Upload the YOLO Model (.pt)')\n",
        "    model_file = st.file_uploader(\"Upload YOLO .pt model file\", type=['pt'],\n",
        "    help=\"Upload the YOLO model (.pt format) to run inference.\")\n",
        "    if model_file:\n",
        "        with open('./session_files/custom_model.pt', \"wb\") as f:\n",
        "            f.write(model_file.getbuffer())\n",
        "        validate_yolo_model_file('./session_files/custom_model.pt')\n",
        "    st.subheader('Step 2: Upload Test Images')\n",
        "    test_zip = st.file_uploader(\"Upload test image zip\", type=['zip'], help=\"Upload a zip file containing your test images in the correct structure (test/ folder).\")\n",
        "    if test_zip:\n",
        "      temp_extract_dir = './session_files/test_structure/'\n",
        "      with zipfile.ZipFile(test_zip, 'r') as zip_ref:\n",
        "          zip_ref.extractall(temp_extract_dir)\n",
        "      st.success(\"Images unzipped successfully!\")\n",
        "      structure_status = check_test_folder_structure(temp_extract_dir)\n",
        "    if model_file and test_zip:\n",
        "        if torch.cuda.is_available():\n",
        "            st.warning(\"Inference will be done on GPU\")\n",
        "            device = torch.device('cuda')\n",
        "        else:\n",
        "            st.warning(\"Inference will be done on CPU\")\n",
        "            device = torch.device('cpu')\n",
        "        if all(structure_status.values()):\n",
        "            for item in os.listdir(temp_extract_dir):\n",
        "                shutil.move(os.path.join(temp_extract_dir, item), os.path.join(parent_directory, item))\n",
        "            shutil.rmtree(temp_extract_dir)\n",
        "            valid_extensions = ('.jpg', '.jpeg', '.png')\n",
        "            for path1 in ['/test/images']:\n",
        "                for filename in os.path.join(parent_directory, path1):\n",
        "                    if not filename.lower().endswith(valid_extensions):\n",
        "                        try:\n",
        "                            os.remove(os.path.join(parent_directory, path1, filename))\n",
        "                        except Exception as e:\n",
        "                            continue\n",
        "            test_images_path = os.path.join(parent_directory, 'test/images')\n",
        "            test_images = os.listdir(test_images_path)\n",
        "            test_count = len(test_images)\n",
        "            st.write(f\"Number of test images: {test_count}\")\n",
        "            for idx,filename in enumerate(test_images):\n",
        "              if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                sample_image_path = filename\n",
        "                break\n",
        "            sample_image = cv2.imread(os.path.join(test_images_path, sample_image_path))\n",
        "            sample_image_rgb = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
        "            st.subheader(\"Adjust Bounding Box Parameters for Sample Image\")\n",
        "            thickness = st.slider(\"Select bounding box thickness\", min_value=1, max_value=10, value=2, step=1, help=\"Choose the thickness of the bounding box lines (1-10).\")\n",
        "            font_scale = st.slider(\"Select font scale\", min_value=0.5, max_value=2.0, value=0.6, step=0.1, help=\"Set the font size for the labels displayed on the bounding boxes.\")\n",
        "            threshold = st.slider(\"Set threshold\", min_value=0, max_value=100, value=70, step=1, help=\"Set the confidence threshold (0-100%) for detecting objects. Only objects with a confidence score above this threshold will be shown.\")\n",
        "            box_color_hex = st.color_picker(\"Select bounding box color\", \"#00FF00\", help=\"Pick a color for the bounding box.\")\n",
        "            box_color_rgb = tuple(int(box_color_hex.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))\n",
        "            st.subheader(\"Run Inference on Sample Image\")\n",
        "            if st.button(\"Run Sample Inference\"):\n",
        "                model = YOLO('./session_files/custom_model.pt').to(device)\n",
        "                st.write(\"Running inference on the sample image...\")\n",
        "                results = model(sample_image,device=device)\n",
        "                detections = results[0].boxes\n",
        "                image_with_boxes = sample_image.copy()\n",
        "                filtered_boxes = [box.xyxy[0].tolist() for box in detections]\n",
        "                scores = [box.conf[0].item() for box in detections]\n",
        "                merged_boxes, merged_scores = filter_and_merge_boxes(filtered_boxes, scores, threshold / 100)\n",
        "                for box, score in zip(merged_boxes, merged_scores):\n",
        "                    x1, y1, x2, y2 = map(int, box)\n",
        "                    class_id = int(detections[0].cls[0].item())\n",
        "                    label = results[0].names[class_id]\n",
        "                    cv2.rectangle(image_with_boxes, (x1, y1), (x2, y2), box_color_rgb, thickness)\n",
        "                    cv2.putText(image_with_boxes, f\"{label} {score:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, box_color_rgb, thickness)\n",
        "                col1, col2 = st.columns(2)\n",
        "                with col1:\n",
        "                    st.image(sample_image_rgb, caption=\"Sample Image\", use_column_width=True)\n",
        "                with col2:\n",
        "                    st.image(image_with_boxes, caption=\"Predicted Image\", use_column_width=True)\n",
        "            st.subheader(\"Run Inference on All Test Images\")\n",
        "            if st.button(\"Run Inference on All Images\"):\n",
        "                st.write(\"Running inference on all test images...\")\n",
        "                try:\n",
        "                    model = YOLO('./session_files/custom_model.pt').to(device)\n",
        "                    inference_folder = './session_files/inference/'\n",
        "                    if not os.path.exists(inference_folder):\n",
        "                        os.makedirs(inference_folder)\n",
        "                    results_list = []\n",
        "                    start_time = time.time()\n",
        "                    for img_name in test_images:\n",
        "                        if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                            img_path = os.path.join(test_images_path, img_name)\n",
        "                            img = cv2.imread(img_path)\n",
        "                            start_time = time.time()\n",
        "                            results = model(img,device=device)\n",
        "                            detections = results[0].boxes\n",
        "                            image_with_boxes = img.copy()\n",
        "                            filtered_boxes = [box.xyxy[0].tolist() for box in detections]\n",
        "                            scores = [box.conf[0].item() for box in detections]\n",
        "                            merged_boxes, merged_scores = filter_and_merge_boxes(filtered_boxes, scores, threshold / 100)\n",
        "                            for box, score in zip(merged_boxes, merged_scores):\n",
        "                                x1, y1, x2, y2 = map(int, box)\n",
        "                                class_id = int(detections[0].cls[0].item())\n",
        "                                label = results[0].names[class_id]\n",
        "                                cv2.rectangle(image_with_boxes, (x1, y1), (x2, y2), box_color_rgb, thickness)\n",
        "                                cv2.putText(image_with_boxes, f\"{label} {score:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, box_color_rgb, thickness)\n",
        "                                results_list.append({\n",
        "                                    \"ImageName\": img_name,\n",
        "                                    \"TimeTaken\": time.time() - start_time,\n",
        "                                    \"LabelID\": class_id,\n",
        "                                    \"Label\": label,\n",
        "                                    \"Score\": score,\n",
        "                                    \"X0-Value\": x1,\n",
        "                                    \"X1-Value\": x2,\n",
        "                                    \"Y0-Value\": y1,\n",
        "                                    \"Y1-Value\": y2\n",
        "                                })\n",
        "                            cv2.imwrite(os.path.join(inference_folder, img_name), image_with_boxes)\n",
        "                        else:\n",
        "                            continue\n",
        "                    total_time = time.time() - start_time\n",
        "                    total_time_minutes = total_time / 60\n",
        "                    total_time_hours = total_time / 3600\n",
        "                    st.success(f\"Inference on all images completed! in ~{total_time_minutes:.2f} minutes / ~{total_time_hours:.2f} hours.\")\n",
        "                    current_date = datetime.now().strftime(\"%Y%m%d\")\n",
        "                    csv_filename = f\"inference_results_{current_date}.csv\"\n",
        "                    csv_path = os.path.join(inference_folder, csv_filename)\n",
        "                    df:pd.DataFrame = pd.DataFrame(data=results_list)\n",
        "                    df['TimeTaken']:pd.Series = df['TimeTaken'].round(6)\n",
        "                    df['Score']:pd.Series = df['Score'].round(6)\n",
        "                    df.to_csv(path_or_buf=csv_path, header=True, encoding='utf-8', mode='w', index=False)\n",
        "                    zip_filename = f\"InferenceResults_{current_date}.zip\"\n",
        "                    shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', inference_folder)\n",
        "                    with open(zip_filename, 'rb') as f:\n",
        "                        st.download_button('Download Inference Results', f, file_name=zip_filename)\n",
        "                except Exception as e:\n",
        "                    st.error(f\"An error occurred during Inference: {str(e)}\")\n",
        "        else:\n",
        "            if test_zip:\n",
        "                st.error(\"Invalid structure! Please upload a zip with 'test/images' folder containing images.\")\n",
        "                display_test_structure_result(structure_status)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0Gh9wSdcn_I"
      },
      "source": [
        "#### Retrieve the External URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXe15FHa8LUP",
        "outputId": "d02088cb-ce48-41f7-eab9-c08b3521a394"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\n",
            "\n",
            "  You can now view your Streamlit app in your browser.\n",
            "\n",
            "  Local URL: http://localhost:8501\n",
            "  Network URL: http://172.28.0.12:8501\n",
            "  External URL: http://34.73.158.238:8501\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!cat logs.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub_DV7QecqJr"
      },
      "source": [
        "#### Start Localtunnel\n",
        "[Help](https://discuss.streamlit.io/t/how-to-launch-streamlit-app-from-google-colab-notebook/42399/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiaT_yYR7FE8",
        "outputId": "abc88a5c-764b-4906-c8b4-8baa15968ad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "your url is: https://rotten-taxes-dance.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWsdyUOqZu34"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SUxalAMecVXr",
        "6K2VhqqncaE_",
        "4NnO9SYncb_e",
        "X5ARHUeDcenY",
        "-hv_4ijsciag",
        "P0Gh9wSdcn_I",
        "Ub_DV7QecqJr"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
